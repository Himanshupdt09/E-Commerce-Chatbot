
# ğŸš€ E-Commerce Chatbot using RAG (LangChain + OpenAI + AstraDB)

A powerful, intelligent chatbot built for answering e-commerce product-related queries using **Retrieval-Augmented Generation (RAG)**. Leveraging **LangChain**, **OpenAI Embeddings**, and **AstraDB**, this solution is optimized for handling headset and earbud product data from Flipkart. The chatbot is deployed via **Flask** on **AWS EC2**, offering a sleek web interface for real-time interaction.

![Chat Demo 1](images/image1.png)
![Chat Demo 2](images/image2.png)

---

## âœ¨ Features

- ğŸ’¡ **Intelligent Q&A system** powered by LLMs  
- ğŸ” **Semantic product search** via OpenAI embeddings  
- âš¡ **Fast vector similarity** with AstraDB  
- ğŸŒ **Real-time web UI** using Flask  
- â˜ï¸ **Fully deployed on AWS EC2**

---

## ğŸ§° Tech Stack

| Component     | Description                                         |
|---------------|-----------------------------------------------------|
| OpenAI        | Embedding generation for product descriptions       |
| LangChain     | RAG pipeline for retrieval and response generation |
| AstraDB       | Cloud-based vector database for semantic search     |
| Flask         | Web application (frontend and backend)              |
| AWS EC2       | Hosting and deployment                              |
| Flipkart Data | Sample product dataset (headphones, earbuds)        |

---

## ğŸ“ Project Structure

```plaintext
ecomm-chatbot/
â”œâ”€â”€ app.py                       # Flask entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flipkart_products.csv    # Product dataset
â”‚
â”œâ”€â”€ ecombot/                     # Core chatbot modules
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html                # HTML UI for chatbot
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css                # UI styling
â”‚
â”œâ”€â”€ images/                      # Demo screenshots
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

1. Product data is parsed and chunked into documents.  
2. OpenAI creates embeddings for each document.  
3. Embeddings + metadata are stored in AstraDB.  
4. LangChain retrieves the most relevant chunks.  
5. An LLM generates a response based on context.  
6. Flask displays the response in the browser.

---

## ğŸ§ª Running Locally

Install dependencies:

```bash
pip install -r requirements.txt
```

Run the Flask server:

```bash
python app.py
```

Open your browser and go to: [http://localhost:5000](http://localhost:5000)

---

## ğŸš€ Deployment

- âœ… Deployed on **AWS EC2**  
- ğŸ—ƒï¸ Uses **AstraDB** for vector search  
- ğŸ§  Powered by **OpenAI** for response generation  
- ğŸ³ Ready for **Docker** containerization

---

## ğŸ”® Future Enhancements

- ğŸ™ï¸ Voice input support  
- ğŸ›’ Multi-category product handling  
- ğŸ“š Chat history and session tracking  
- ğŸ¯ Query filters (e.g., brand, price, rating)

---
